<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> Learning Out Loud - (LOL)</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on  Learning Out Loud - (LOL)</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Mar 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Papers &amp; Articles I enjoyed</title>
      <link>http://localhost:1313/post/interesting_papers/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/interesting_papers/</guid>
      <description></description>
    </item>
    <item>
      <title>Unpacked: Double Machine Learning</title>
      <link>http://localhost:1313/post/double_ml/</link>
      <pubDate>Tue, 04 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/double_ml/</guid>
      <description>&lt;p&gt;You&amp;rsquo;ve all heard about Machine Learning. Some say it&amp;rsquo;s amaying, I say it&amp;rsquo;s meh. I would rather &lt;em&gt;double it&lt;/em&gt; and give it to the next person which, happend to be you (see the pun I just did ?). You guessed it today we will talk about Double Machine Learning.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt; For now we will focus on how Double ML is used to compute ATE. CATE may come later.&lt;/p&gt;&#xA;&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&lt;p&gt;Before diving into this subject we need to talk about &lt;strong&gt;causation&lt;/strong&gt; and &lt;strong&gt;causal inference&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Unpacked: Eigenvalues &amp; Eigenvectors</title>
      <link>http://localhost:1313/post/eigenvalues_and_eigenvectors/</link>
      <pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/eigenvalues_and_eigenvectors/</guid>
      <description>&lt;!-- raw HTML omitted --&gt;&#xA;&lt;p&gt;I&amp;rsquo;ve heard the terms &lt;strong&gt;eigenvalues&lt;/strong&gt; and &lt;strong&gt;eigenvectors&lt;/strong&gt; countless times, but if I&amp;rsquo;m being honest, I&amp;rsquo;ve never truly grasped their meaning. That&amp;rsquo;s kind of a bummer as they seem to appear everywhere from plain mathematics to machine learning which makes it feel like something worth understanding.&lt;/p&gt;&#xA;&lt;p&gt;This is my attempt to break them down in a way that makes sense, not just mathematically but intuitively. Let&amp;rsquo;s start from the basics and build up from there.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
